{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(local_data, window=28, stride=28):\n",
    "    mat_data = []\n",
    "    idx = 0\n",
    "    while idx+window <= local_data.shape[0]:\n",
    "        mat_data.append(local_data[idx:idx+window])\n",
    "        idx += stride\n",
    "    mat_data = np.array(mat_data)\n",
    "    return mat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data_dict, T, window=28, stride=28):\n",
    "    INPUTDIM = (28,40)\n",
    "    OUTPUTDIM = (28,7)\n",
    "    population = pd.read_csv('..\\data\\Popolazione_province.csv', index_col=0)\n",
    "\n",
    "    # Create training set\n",
    "    mat_data_ = build_sequences(data_dict['BO'][0:T], window=window, stride=stride)\n",
    "    n_windows = mat_data_.shape[0]\n",
    "    test_labels = ['MO','RO', 'VI', 'AL', 'BI', 'PN', 'MB']\n",
    "    input_train = np.ones((n_windows,INPUTDIM[0],INPUTDIM[1]))\n",
    "    output_train = np.ones((n_windows,OUTPUTDIM[0], OUTPUTDIM[1]))\n",
    "    i=0\n",
    "    j=0\n",
    "    for sigla, local_data in data_dict.items():\n",
    "        local_data = local_data[0:T]/population['Residenti'][sigla]*100000\n",
    "        mat_data = build_sequences(local_data, window=window, stride=stride)\n",
    "        if not sigla in test_labels:\n",
    "            input_train[:,:,i]=mat_data\n",
    "            i += 1\n",
    "        else:\n",
    "            output_train[:,:,j]=mat_data\n",
    "            j += 1\n",
    "\n",
    "    # Create test set\n",
    "    mat_data_ = build_sequences(data_dict['BO'][T:], window=window, stride=stride)\n",
    "    n_windows_test = mat_data_.shape[0]\n",
    "    input_test = np.ones((n_windows_test,INPUTDIM[0],INPUTDIM[1]))\n",
    "    output_test = np.ones((n_windows_test,OUTPUTDIM[0], OUTPUTDIM[1]))\n",
    "    i=0\n",
    "    j=0\n",
    "    for sigla, local_data in data_dict.items():\n",
    "        local_data = local_data[T:]/population['Residenti'][sigla]*100000\n",
    "        mat_data = build_sequences(local_data, window=window, stride=stride)\n",
    "        if not sigla in test_labels:\n",
    "            input_test[:,:,i]=mat_data\n",
    "            i += 1\n",
    "        else:\n",
    "            output_test[:,:,j]=mat_data\n",
    "            j += 1\n",
    "    \n",
    "    return input_train, output_train, input_test, output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from the file\n",
    "with open('..\\data\\provinces_fit.pickle', 'rb') as file:\n",
    "    provinces_fitted = pickle.load(file)\n",
    "\n",
    "fit_data_dict = {}\n",
    "for sigla, object in provinces_fitted.items():\n",
    "    fit_data_dict.update({sigla: object.predict(np.arange(0,1173))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, output_train, input_test, output_test = build_dataset(fit_data_dict, T=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dictionary from the file\n",
    "# with open('..\\data\\mat_dict.pickle', 'rb') as file:\n",
    "#     mat_dict = pickle.load(file)\n",
    "# n_windows = mat_dict['BO'].shape[0]\n",
    "\n",
    "# INPUTDIM = (28,40)\n",
    "# OUTPUTDIM = (28,7)\n",
    "# test_labels = ['MO','RO', 'VI', 'AL', 'BI', 'PN', 'MB']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create traing set\n",
    "\n",
    "# input_train = np.ones((n_windows,INPUTDIM[0],INPUTDIM[1]))\n",
    "# output_train = np.ones((n_windows,OUTPUTDIM[0], OUTPUTDIM[1]))\n",
    "# i=0\n",
    "# j=0\n",
    "# for sigla, local_data in mat_dict.items():\n",
    "#     if not sigla in test_labels:\n",
    "#         input_train[:,:,i]=local_data\n",
    "#         i += 1\n",
    "#     else:\n",
    "#         output_train[:,:,j]=local_data\n",
    "#         j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating trimmed dataset for test set\n",
    "\n",
    "# # Load the dictionary from the file\n",
    "# with open('../data/new_pos_dict.pickle', 'rb') as file:\n",
    "#     new_pos_dict = pickle.load(file)\n",
    "\n",
    "# T = 1200\n",
    "# t0 = 801\n",
    "# mat_dict_test = build_sequences(new_pos_dict, t0, T, stride=14)\n",
    "# n_windows_test = mat_dict_test['BO'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create test set\n",
    "# input_test = np.ones((n_windows_test,INPUTDIM[0],INPUTDIM[1]))\n",
    "# output_test = np.ones((n_windows_test,OUTPUTDIM[0], OUTPUTDIM[1]))\n",
    "# i=0\n",
    "# j=0\n",
    "# for sigla, local_data in mat_dict_test.items():\n",
    "#     if not sigla in test_labels:\n",
    "#         input_test[:,:,i]=local_data\n",
    "#         i += 1\n",
    "#     else:\n",
    "#         output_test[:,:,j]=local_data\n",
    "#         j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved\n"
     ]
    }
   ],
   "source": [
    "# Saving data\n",
    "save_flag = False\n",
    "#save_flag = True\n",
    "if save_flag:\n",
    "    np.save('../data/input_train.npy', input_train)\n",
    "    np.save('../data/output_train.npy', output_train)\n",
    "    np.save('../data/input_test.npy', input_test)\n",
    "    np.save('../data/output_test.npy', output_test)\n",
    "    print('Dataset saved')\n",
    "else:\n",
    "    print('Dataset NOT saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
